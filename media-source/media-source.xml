<!DOCTYPE HTML>
<html>
  <head>
    <title>Media Source Extensions</title>
    <link rel="stylesheet" href="video-working-draft.css" />
    <link rel="stylesheet" href="main.css" />
    <link type="text/css" rel="stylesheet" href="http://www.w3.org/StyleSheets/TR/w3c-ed.css" />
    <style type="text/css">
          <!-- For discussion of open issues. -->
          .issue {
          padding:    1em;
          margin: 1em 0em 0em;
          border: 1px solid #f00;
          background: #fcc;
          }
          .issue::before {
          content:    "Issue";
          display:    block;
          width:  150px;
          margin: -1.5em 0 0.5em 0;
          font-weight:    bold;
          border: 1px solid #f00;
          background: #fff;
          padding:    3px 1em;
          }

	  div.nonnormative { color: green; margin: 2em 0 2em 0em; padding: 0.5em 1em; border: none; background: #DDFFDD; }
	  .nonnormative:before { display: table; margin: -1em -0.5em -0.5em auto; width: auto; content: 'This section is non-normative.'; color: black; font-style: italic; border: solid 2px; background: white; padding: 0 0.25em; }

	  <!-- Copied from video-working-draft.css .domintro -->
	  .example { color: green; margin: 2em 0 2em 2em; padding: 0.5em 1em; border: none; background: #DDFFDD; }
	  hr + dl.example, div.impl + dl.domintro { margin-top: 2.5em; margin-bottom: 1.5em; }
	  dl.example dt, dl.domintro dt * { color: black; text-decoration: none; }
	  dl.example dd { margin: 0.5em 0 1em 2em; padding: 0; }
	  dl.example dd p { margin: 0.5em 0; }

	  .example:before { display: table; margin: -1em -0.5em -0.5em auto; width: auto; content: 'This box is non-normative. Implementation requirements are given below this box.'; color: black; font-style: italic; border: solid 2px; background: white; padding: 0 0.25em; }
    </style>
  </head>
  <body>
    <div class="head">
      <p><a href="http://www.w3.org/"><img src="http://www.w3.org/Icons/w3c_home" alt="W3C" width="72" height="48" /></a></p>
      <h1>Media Source Extensions</h1>
      <h2>W3C Editor's Draft 17 August 2012</h2>
      <dl>
	<dt>Latest published version:</dt>
	<dd>Not yet published</dd>
	<dt>Latest editor's draft:</dt>
	<dd><a href="http://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html">http://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html</a></dd>
	<dt>Editors:</dt>
	<dd>Aaron Colwell, Google, Inc.</dd>
	<dd>Adrian Bateman, Microsoft Corporation</dd>
	<dd>Mark Watson, Netflix, Inc.</dd>
	<dt>Bug/Issue lists:</dt>
	<dd><a href='http://w3.org/brief/Mjcw'>Bugzilla</a>, <a href='http://www.w3.org/html/wg/tracker/products/20'>Tracker</a></dd>
	<dt>Discussion list:</dt>
	<dd><a href='http://lists.w3.org/Archives/Public/public-html-media/'>public-html-media@w3.org</a></dd>
	<dt>Test Suite:</dt>
	<dd>None yet</dd>

      </dl>
    </div>
    <p class="copyright"><a href="http://www.w3.org/Consortium/Legal/2002/ipr-notice-20021231#Copyright">Copyright</a> &#169; 2012 <a href="http://www.w3.org/"><abbr title="World Wide Web Consortium">W3C</abbr></a><sup>&#174;</sup> (<a href="http://www.csail.mit.edu/"><abbr title="Massachusetts Institute of Technology">MIT</abbr></a>, <a href="http://www.ercim.eu/"><abbr title="European Research Consortium for Informatics and Mathematics">ERCIM</abbr></a>, <a href="http://www.keio.ac.jp/">Keio</a>), All Rights Reserved. W3C <a href="http://www.w3.org/Consortium/Legal/2002/ipr-notice-20021231#Legal_Disclaimer">liability</a>, <a href="http://www.w3.org/Consortium/Legal/2002/ipr-notice-20021231#W3C_Trademarks">trademark</a> and <a href="http://www.w3.org/Consortium/Legal/copyright-documents">document use</a> rules apply.</p>

    <h2>Status of this Document</h2>
      
    <p><em>
      This section describes the status of this document at the time of its publication. Other documents may supersede this document.
      A list of current W3C publications and the latest revision of this technical report can be found in the
      <a href="http://www.w3.org/TR/">W3C technical reports index</a> at http://www.w3.org/TR/.
    </em></p>

    <p>
      This document was published by the <a href="http://www.w3.org/html/wg/">HTML working group</a> as an Editor's Draft.
      Please submit comments regarding this document by using the W3C's (<a href="https://www.w3.org/Bugs/Public/enter_bug.cgi?product=HTML%20WG&amp;component=Media%20Source%20Extensions">public bug database</a>) with the product set to <kbd>HTML WG</kbd> and the component set to
      <kbd>Media Source Extensions</kbd>.
      If you cannot access the bug database, submit comments to <a href="mailto:public-html-media@w3.org">public-html-media@w3.org</a>
      (<a href="mailto:public-html-media-request@w3.org?subject=subscribe">subscribe</a>,
      <a href="http://lists.w3.org/Archives/Public/public-html-media/">archives</a>) and arrangements will be made to transpose the comments to the bug database.
      All feedback is welcome.
    </p>

    <p>
      Publication as a Editor's Draft does not imply endorsement by the W3C Membership. This is a draft document and may be updated,
      replaced or obsoleted by other documents at any time. It is inappropriate to cite this document as other than work in progress.
    </p>
    <p>
      This document was produced by a group operating under the <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/">5 February 2004 W3C Patent Policy</a>.
      W3C maintains a <a href="http://www.w3.org/2004/01/pp-impl/40318/status" rel="disclosure">public list of any patent disclosures</a> made in connection with
      the deliverables of the group; that page also includes instructions for disclosing a patent. An individual who has actual knowledge of a patent which
      the individual believes contains <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#def-essential">Essential Claim(s)</a> must disclose the
      information in accordance with <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#sec-Disclosure">section 6 of the W3C Patent Policy</a>.
    </p>     

    <h2>Abstract</h2>
    <p>
      This proposal extends HTMLMediaElement to allow 
      JavaScript to generate media streams for playback. 
      Allowing JavaScript to generate streams facilitates a variety of use 
      cases like adaptive streaming and time shifting live streams.
    </p>

    <h2>Table of Contents</h2>

    <ul id="toc" class="toc">
      <li><a href="#introduction">1. Introduction</a></li>
      <li>
	<ul>
	  <li><a href="#goals">1.1 Goals</a></li>
	  <li><a href="#definitions">1.2 Definitions</a></li>
	</ul>
      </li>
      <li><a href="#source-buffer-model">2. Source Buffer Model</a></li>
      <li>
	<ul>
	  <li><a href="#source-buffer-create">2.1. Creating Source Buffers</a></li>
	  <li><a href="#source-buffer-remove">2.2. Removing Source Buffers</a></li>
	  <li><a href="#source-buffer-basic-append">2.3. Basic appending model</a></li>
	  <li><a href="#source-buffer-init-segment-constraints">2.4.  Initialization Segment constraints</a></li>
	  <li><a href="#source-buffer-media-segment-constraints">2.5. Media Segment constraints</a></li>
	  <li><a href="#source-buffer-first-init-segment">2.6. Appending the first Initialization Segment</a></li>
	  <li><a href="#source-buffer-media-segment-unbuffered">2.7. Appending a Media Segment to an unbuffered region</a></li>
	  <li><a href="#source-buffer-overlapping-segments">2.8. Appending a Media Segment over a buffered region</a></li>
	  <li><a href="#source-buffer-to-track-buffer">2.9. Source Buffer to Track Buffer transfer</a></li>
	  <li><a href="#source-buffer-segment-eviction">2.10. Media Segment Eviction</a></li>
	  <li><a href="#source-buffer-timestamp-offsets">2.11. Applying Timestamp Offsets</a></li>
	  <li><a href="#source-buffer-duration-updates">2.12. Presentation Duration Updates</a></li>
	</ul>
      </li>
      <li><a href="#mediasource">3. MediaSource Object</a>
	<ul>
	  <li><a href="#mediasource-methods">3.1. Methods and Attributes</a></li>
	  <li><a href="#mediasource-events">3.2. Event Summary</a></li>
	  <li><a href="#mediasource-algorithms">3.3. Algorithms</a></li>
	</ul>
      </li>
      <li><a href="#sourcebuffer">4. SourceBuffer Object</a></li>
      <li><a href="#sourcebufferlist">5. SourceBufferList Object</a>
	<ul>
	  <li><a href="#sourcebufferlist-methods">5.1. Methods and Attributes</a></li>
	  <li><a href="#sourcebufferlist-events">5.2. Event Summary</a></li>
	</ul>
      </li>
      <li><a href="#byte-stream-formats">6. Byte Stream Formats</a></li>
      <li>
	<ul>
	  <li><a href="#webm">6.1 WebM</a></li>
	  <li><a href="#iso">6.2 ISO Base Media File Format</a></li>
	</ul>
      </li>
      <li><a href="#examples">7. Examples</a></li>
      <li><a href="#revision-history">8. Revision History</a></li>
    </ul>

    <h2 id="introduction">1. Introduction</h2>
    <p>This proposal allows JavaScript to dynamically construct media streams for &lt;audio&gt; and &lt;video&gt;. 
       It defines objects that allow JavaScript to pass media segments to an <videoref name="htmlmediaelement">HTMLMediaElement</videoref>.
       A buffering model is also included to describe how the user agent should act when different media segments are 
       appended at different times. Byte stream specifications for WebM &amp; ISO Base Media File Format are given to specify the
       expected format of media segments used with these extensions.</p>
    <img src="pipeline_model.png" />

    <h3 id="goals">1.1. Goals</h3>
    <p>This proposal was designed with the following goals in mind:</p>
    <ul>
      <li>Allow JavaScript to construct media streams independent of how the media is fetched.</li>
      <li>Define a splicing and buffering model that facilitates use cases like adaptive streaming, ad-insertion, time-shifting, and video editing.</li>
      <li>Minimize the need for media parsing in JavaScript.</li>
      <li>Leverage the browser cache as much as possible.</li>
      <li>Provide byte stream definitions for WebM &amp; the ISO Base Media File Format.</li>
      <li>Not require support for any particular media format or codec.</li>
    </ul>

    <h3 id="definitions">1.2. Definitions</h3>

    <h4 id="init-segment">1.2.1. Initialization Segment</h4>
    <p>A sequence of bytes that contains all of the initialization information required to decode a sequence of <media-segments/>. This includes codec initialization data, trackID mappings for multiplexed segments, and timestamp offsets (e.g. edit lists).</p>

    <dl class="example">
      <p>Container specific examples of initialization segments:</p>
      <dt>ISO Base Media File Format</dt>
      <dd>A <iso-box>moov</iso-box> box.</dd>
      <dt>WebM</dt>
      <dd>The concatenation of the the EBML Header, Segment Header, Info element, and Tracks element.</dd>
    </dl>

    <h4 id="media-segment">1.2.2. Media Segment</h4>
    <p>A sequence of bytes that contain packetized &amp; timestamped media data for a portion of the presentation timeline. Media segments are always associated with the most recently appended <init-segment/>.</p>

    <dl class="domintro">
      <p>Container specific examples of media segments:</p>
      <dt>ISO Base Media File Format</dt>
      <dd>A <iso-box>moof</iso-box> box followed by one or more <iso-box>mdat</iso-box> boxes.</dd>
      <dt>WebM</dt>
      <dd>A Cluster element</dd>
    </dl>

    <h4 id="source-buffer">1.2.3. Source Buffer</h4>
    <p>A hypothetical buffer that contains a distinct sequence of <init-segments/> &amp; <media-segments/>. When <media-segments/> are passed to <append/> they update the state of this buffer. The source buffer only allows a single <media-segment/> to cover a specific point in the presentation timeline of each track. If a <media-segment/> gets appended that contains media data overlapping (in presentation time) with media data from an existing segment, then the new media data will override the old media data. Since <media-segments/> depend on <init-segments/> the source buffer is also responsible for maintaining these associations. During playback, the media element pulls segment data out of the source buffers, demultiplexes it if necessary, and enqueues it into <track-buffers/> so it will get decoded and displayed. <buffered/> describes the time ranges that are covered by <media-segments/> in the source buffer.</p>

    <h4 id="active-source-buffers">1.2.4. Active Source Buffers</h4>
    <p>The set of <source-buffers/> that are providing the <videoref name="dom-videotrack-selected">selected video track</videoref>, the <videoref name="dom-audiotrack-enabled">enabled audio tracks</videoref>, and the <videoref name="dom-texttrack-showing">&quot;showing&quot;</videoref> or <videoref name="dom-texttrack-hidden">&quot;hidden&quot;</videoref> text tracks. This is a subset of all the source buffers associated with a specific <MediaSource/> object. See <a href="#active-source-buffer-changes">Changes to selected/enabled track state</a> for details.</p>


    <h4 id="track-buffer">1.2.5. Track Buffer</h4>
    <p>A hypothetical buffer that represents initialization and media data for a single <audio-track/>, <video-track/>, or <text-track/> that has been queued for playback. This buffer may not exist in actual implementations, but it is intended to represent media data that will be decoded no matter what <media-segments/> are appended to update the <source-buffer/>. This distinction is important when considering appends that happen close to the current playback position. See <a href="#source-buffer-to-track-buffer">Source Buffer to Track Buffer transfer</a> for details.</p>


    <h4 id="random-access-point">1.2.6. Random Access Point</h4>
    <p>A position in a <media-segment/> where decoding and continuous playback can begin without relying on any previous data in the segment. For video this tends to be the location of I-frames. In the case of audio, most audio frames can be treated as a random access point. Since video tracks tend to have a more sparse distribution of random access points, the location of these points are usually considered the random access points for multiplexed streams.</p>

    <h4 id="presentation-start-time">1.2.7. Presentation Start Time</h4>
    <p>The presentation start time is the earliest time point in the presentation and specifies the <videoref name="initial-playback-position">initial playback position</videoref> and <videoref name="earliest-possible-position">earliest possible position</videoref>. All presentations created using this specification have a presentation start time of 0. Appending <media-segments/> with negative timestamps will cause playback to terminate with a <videoref name="dom-mediaerror-media_err_decode">MediaError.MEDIA_ERR_DECODE</videoref> error unless <timestampOffset/> is used to make the timestamps greater than or equal to 0.</p>

    <h2 id="source-buffer-model">2. Source Buffer Model</h2>
    <p>The subsections below outline the buffering model for this proposal. It describes how to add and remove <source-buffers/> from the presentation and describes the various rules and behaviors associated with appending data to an individual <source-buffer/>. At the highest level, the web application simply creates <source-buffers/> and appends a sequence of <init-segments/> and <media-segments/> to update the buffer's state. The media element pulls media data out of the <source-buffers/>, plays it, and fires events just like it would if a normal URL was passed to the <media-src/> attribute. The web application is expected to monitor media element events to determine when it needs to append more <media-segments/>.</p>

    <h3 id="source-buffer-create">2.1. Creating Source Buffers</h3>
    <p><SourceBuffer/> objects can be created once a <MediaSource/> object enters the <open/> state. The application calls <addSourceBuffer/> with a type string that indicates the format of the data it intends to append to the new SourceBuffer. If the user agent supports the format and has sufficient resources, a new <SourceBuffer/> object is created, added to <sourceBuffers/>, and returned by the method. If the user agent doesn't support the specified format or can't support another <SourceBuffer/> then it will throw an appropriate exception to signal why the request couldn't be satisfied.</p>

    <h3 id="source-buffer-remove">2.2. Removing Source Buffers</h3>
    <p>Removing a <SourceBuffer/> with <removeSourceBuffer/> releases all resources associated with the object. This includes destroying the all the segment data, <track-buffers/>, and decoders. The media element will also remove the appropriate tracks from <audiotracks/>, <videotracks/>,  &amp; <texttracks/> and fire the necessary <videoref name="handler-tracklist-onchange">change</videoref> events. Playback may become degraded or stop if the currently selected <video-track/> or the only enabled <audio-tracks/> are removed.</p>

    <h3 id="source-buffer-basic-append">2.3. Basic appending model</h3>
    <p>Updating the state of a <source-buffer/> requires appending at least one <init-segment/> and one or more <media-segments/> via <append/>. The following list outlines some of the basic rules for appending segments.
      <ul>
	<li>The first segment appended must be an <init-segment/>.</li>
	<li>All <media-segments/> are associated with the most recently appended <init-segment/>.</li>
	<li>A whole segment must be appended before another segment can be started unless <abort/> is called.</li>
	<li>Segments can be appended in pieces. (i.e. A 4096 byte segment can be spread across four 1024 byte calls to <append/>).</li>
	<li>If a <media-segment/> requires different configuration information (e.g. codec parameters, new internal trackIDs, metadata) from what is in the most recently appended <init-segment/>, a new <init-segment/> with the new configuration information must be appended before the <media-segment/> requiring this information is appended.</li>
	<li>A new <media-segment/> can overlap, in presentation time, a segment that was previously appended. The new segment will override the previous data.</li>
	<li>Media segments can be appended in any order.<br/>Note: In practice finite buffer space and maintaining uninterrupted playback will bias appending towards time increasing order near the current playback position. Out of order appends facilitate adaptive streaming, ad insertion, and video editing use cases.</li>
	<li>The media element may start copying data from a <media-segment/> to the <track-buffers/> before the entire segment has been appended. This prevents unnecessary delays for <media-segments/> that cover a large time range.</li>
      </ul>
    </p>

    <h3 id="source-buffer-init-segment-constraints">2.4. Initialization Segment constraints</h3>
    <p>To simplify the implementation and facilitate interoperability, a few constraints are placed on the <init-segments/> that are appended to a specific <SourceBuffer/>:
      <ul>
	<li>The number and type of tracks must be consistent across all <init-segments/>. <br/>For example, if the first <init-segment/> has 2 audio tracks and 1 video track, then all <init-segments/> that follow, for this <SourceBuffer/> must describe 2 audio tracks and 1 video track.</li>
	<li>Internal trackIDs do not need to be the same across <init-segments/> only if the segment describes one track of each type.<br/> For example, if an <init-segment/> describes a single audio track and a single video track, the internal trackIDs do not need to be the same.</li>
	<li>Internal trackIDs must be the same across <init-segments/> if multiple tracks for a single type are described. (e.g. 2 audio tracks).</li>
	<li>Codecs changes are not allowed. <br/> For example, you can't have an <init-segment/> that specifies a single AAC track and then follows it with one that contains AMR-WB. Support for multiple codecs is handled with multiple <SourceBuffer/> objects.</li>
	<li>Video frame size changes are allowed and must be supported seamlessly.<br/> Note: This will cause the &lt;video&gt; display region to change size if you don't use CSS or HTML attributes (width/height) to constrain the element size.</li>
	<li>Audio channel count changes are allowed, but they may not be seamless and could trigger downmixing.<br/> Note: This is a quality of implementation issue because changing the channel count may require reinitializing the audio device, resamplers, and channel mixers which tends to be audible.</li>
      </ul>
    </p>

    <h3 id="source-buffer-media-segment-constraints">2.5. Media Segment constraints</h3>
    <p>To simplify the implementation and facilitate interoperability, a few constraints are placed on the <media-segments/> that are appended to a specific <SourceBuffer/>:
      <ul>
	<li>All timestamps must be mapped to the same presentation timeline.</li>
	<li>Segments should start with a <random-access-point/> to facilitate seamless splicing at the segment boundary.</li>
	<li>Gaps between <media-segments/> that are smaller than the audio frame size are allowed and should be rendered as silence. Such gaps should not be reflected by <buffered/>.<br/>Note: This is intended to simplify switching between audio streams where the frame boundaries don't always line up across encodings (e.g. Vorbis).</li>
      </ul>
    </p>

    <h3 id="source-buffer-first-init-segment">2.6. Appending the first Initialization Segment</h3>
    <p>Once a new <SourceBuffer/> has been created, it expects an <init-segment/> to be appended first. This first segment indicates the number and type of streams contained in the <media-segments/> that follow. This allows the media element to configure the necessary decoders and output devices. This first segment can also cause a <ready-state/> transition to <have-metadata/> if this is the first <SourceBuffer/>, or if it is the first track of a specific type (i.e. first audio, first video track, or first text track). If neither of the conditions hold then the tracks for this new <SourceBuffer/> will just appear as disabled tracks and won't affect the current <ready-state/> until they are selected. The media element will also add the appropriate tracks to the <audiotracks/>, <videotracks/>, &amp; <texttracks/> collections and fire the necessary <videoref name="handler-tracklist-onchange">change</videoref> events. The description for <append/> contains all the details.</p>
    
    <h3 id="source-buffer-media-segment-unbuffered">2.7. Appending a Media Segment to an unbuffered region</h3>
    <p>If a <media-segment/> is appended to a time range that is not covered by existing segments in the <source-buffer/>, then its data is copied directly into the <source-buffer/>. Addition of this data may trigger <ready-state/> transitions depending on what other data is buffered and whether the media element has determined if it can start playback. Calls to <buffered/> will always reflect the current <timeranges/> buffered in the <SourceBuffer/>.</p>

    <h3 id="source-buffer-overlapping-segments">2.8. Appending a Media Segment over a buffered region</h3>
    <p>There are several ways that <media-segments/> can overlap segments in the <source-buffer/>. Behavior for the different overlap situations are described below. If more than one overlap applies, then the <a href="#source-buffer-overlap-start">start overlap</a> gets resolved first, followed by any <a href="#source-buffer-overlap-complete">complete overlaps</a>, and finally the <a href="#source-buffer-overlap-end">end overlap</a>. If a segment contains multiple tracks then the overlap is resolved independently for each track.</p>

    <h4 id="source-buffer-overlap-complete">2.8.1 Complete Overlap</h4>
    <img src="complete_overlap.png"/>
    <p>The figure above shows how the <source-buffer/> gets updated when a new <media-segment/> completely overlaps a segment in the buffer. In this case, the new segment completely replaces the old segment.</p>

    <h4 id="source-buffer-overlap-start">2.8.2 Start Overlap</h4>
    <img src="start_overlap.png"/>
    <p>The figure above shows how the <source-buffer/> gets updated when the beginning of a new <media-segment/> overlaps a segment in the buffer. In this case the new segment replaces all the old media data in the overlapping region. Since <media-segments/> are constrained to starting with <random-access-points/>, this provides a seamless transition between segments.</p>
    <p>The one case that requires special attention is where an audio frame overlaps with the start of the new <media-segment/>. The base level behavior that must be supported requires dropping the old audio frame that overlaps the start of the new segment and inserting silence for the small gap that is created. A higher quality implementation could support outputting a portion of the old segment and all of the new segment or crossfade during the overlapping region. This is a quality of implementation issue. The key property here though is the small silence gap should not be reflected in the ranges reported by <buffered/>.</p>

    <h4 id="source-buffer-overlap-end">2.8.3 End Overlap</h4>
    <img src="end_overlap.png"/>
    <p>The figure above shows how the <source-buffer/> gets updated when the end of a new <media-segment/> overlaps a segment in the buffer. In this case, the media element tries to keep as much of the old segment as possible. The amount saved depends on where the closest <random-access-point/>, in the old segment, is to the end of the new segment. In the case of audio, if the gap is smaller than the size of an audio frame, then the media element should insert silence for this gap and not reflect it in <buffered/>.</p>
      <p>An implementation may keep old segment data before the end of the new segment to avoid creating a gap if it wishes. Doing this though can significantly increase implementation complexity and could cause delays at the splice point. The key property that must be preserved is the entirety of the new segment gets added to the <source-buffer/> and it is up to the implementation how much of the old segment data is retained. The web application can use <buffered/> to determine how much of the old segment was preserved.</p>

    <h4 id="source-buffer-overlap-middle">2.8.4 Middle Overlap</h4>
    <img src="middle_overlap.png"/>
    <p>The figure above shows how the <source-buffer/> gets updated when the new <media-segment/> is in the middle of the old segment. This condition is handled by first resolving the <a href="#source-buffer-overlap-start">start overlap</a> and then resolving the <a href="#source-buffer-overlap-end">end overlap</a>.</p>

    <h3 id="source-buffer-to-track-buffer">2.9. Source Buffer to Track Buffer transfer</h3>
    <p>The <source-buffer/> represents the media that the web application would like the media element to play. The <track-buffer/> contains the data that will actually get decoded and rendered. In most cases the <track-buffer/> will simply contain a subset of the <source-buffer/> near the current playback position. These two buffers start to diverge though when <media-segments/> that overlap or are very close to the current playback position are appended. Depending on the contents of the new <media-segment/> it may not be possible to switch to the new data immediately because there isn't a <random-access-point/> close enough to the current playback position. The quality of the implementation determines how much data is considered "in the <track-buffer/>". It should transfer data to the <track-buffer/> as late as possible whilst maintaining seamless playback. Some implementations may be able to instantiate multiple decoders or decode the new data significantly faster than real-time to achieve a seamless splice immediately. Other implementations may delay until the next <random-access-point/> before switching to the newly appended data. Notice that this difference in behavior is only observable when appending close to the current playback position. The <track-buffer/> represents a media subsegment, like a group of pictures or something with similar decode dependencies, that the media element commits to playing. This commitment may be influenced by a variety of things like limited decoding resources, hardware decode buffers, a jitter buffer, or the desire to limit implementation complexity.</p>
    
    <p>Here is an example to help clarify the role of the <track-buffer/>. Say the current playback position has a timestamp of 8 and the media element pulled frames with timestamp 9 &amp; 10 into the track buffer. The web application then appends a higher quality <media-segment/> that starts with a <random-access-point/> at timestamp 9. The <source-buffer/> will get updated with the higher quality data, but the media element won't be able to switch to this higher quality data until the next <random-access-point/> at timestamp 20. This is because a frame for timestamp 9 is already in the track buffer. As you can see the track buffer represents the "point of no return." for decoding. If a seek occurs the media element may choose to use the higher quality data since a seek might imply flushing the <track-buffer/> and the user expects a break in playback.</p>


    <h3 id="source-buffer-segment-eviction">2.10. Media Segment Eviction</h3>
    <p>When a new <media-segment/> is appended, memory constraints may cause previously appended segments to get evicted from the <source-buffer/>. The eviction algorithm is implementation dependent, but segments that aren't likely to be needed soon are the most likely to get evicted. The <buffered/> attribute allows the web application to monitor what time ranges are currently buffered in the <source-buffer/>.</p>

    <h3 id="source-buffer-timestamp-offsets">2.11. Applying Timestamp Offsets</h3>
    <p>For some use cases like ad-insertion or seamless playlists, the web application may want to insert a <media-segment/> in the presentation timeline at a location that is different than what the internal timestamps indicate. This can be accomplished by using the <timestampOffset/> attribute on the <SourceBuffer/> object. The value of <timestampOffset/> is added to all timestamps inside a <media-segment/> before the contents of that segment are added to the <source-buffer/>. The <timestampOffset/> applies to an entire media segment. An exception is thrown if the application tries to update the attribute when only part of a media segment has been appended. Both positive or negative offsets can be assigned to <timestampOffset/>. If an offset causes a <media-segment/> timestamp to get converted to a time before the <presentation-start-time/>, playback will terminate with a <videoref name="dom-mediaerror-media_err_decode">MediaError.MEDIA_ERR_DECODE</videoref> error.</p>

    <p>Here is a simple example to clarify how <timestampOffset/> can be used. Say I have two sounds I want to play in sequence. The first sound is 5 seconds long and the second one is 10 seconds. Both sound files have timestamps that start at 0. First append the <init-segment/> and all <media-segments/> for the first sound. Now set <timestampOffset/> to 5 seconds. Finally append the <init-segment/> and <media-segments/> for the second sound. This will result in a 15 second presentation that plays the two sounds in sequence.</p>

    <h3 id="source-buffer-duration-updates">2.12. Presentation Duration Updates</h3>
    <p>The sections below describe the various ways that the presentation duration can be updated. Whenever the <duration/> attribute changes value, the HTMLMediaElement.duration is updated to the same value and the appropriate <videoref name="event-media-durationchange">durationchange</videoref> event is fired on that object.</p>

    <h4 id="source-buffer-duration-updates-explicit">2.12.1 Explicit Duration</h4>
    <p>The web application can explicitly set the presentation duration by setting the <duration/> attribute. If any <SourceBuffer/> objects in <sourceBuffers/> has media data beyond the new duration, this data is removed from the <SourceBuffer/> object. This ensures that <buffered/> never reports any ranges beyond the current duration. If the current playback position is beyond the new duration, then update HTMLMediaElement.currentTime to the new duration and run the seeking algorithm.</p>

    <h4 id="source-buffer-duration-updates-implicit">2.12.2 Implicit Duration</h4>
    <p>If the <duration/> attribute isn't explicitly set before the first <init-segment/> is appended, then the presentation duration will get implicitly set. If the first initialization segment appended contains duration information then the <duration/> attribute will be set to that value. If the first initialization segment does not contain any duration information then the <duration/> attribute will be set to positive Infinity to indicate that duration isn't known yet.</p>

    <h4 id="source-buffer-duration-updates-append">2.12.3 Appending Beyond Duration</h4>
    <p>Any time a <media-segment/> that goes beyond the current value of the <duration/> attribute is appended to a <SourceBuffer/>, the <duration/> attribute will get updated to end timestamp of the <media-segment/>.</p>

    <h4 id="source-buffer-duration-updates-eos">2.12.4 End of Stream Duration</h4>
    <p>When <endOfStream/> gets called without an error, the <duration/> attribute will get updated to the highest end timestamp across all <SourceBuffer/> objects in <sourceBuffers/>. This allows the duration to properly reflect the end of the appended <media-segments/>. For example, if the duration was explicitly set to 10 seconds and only media segments for 0 to 5 seconds were appended before <endOfStream/> was called, then the duration will get updated to 5 seconds.</p>

    <h2 id="mediasource">3. MediaSource Object</h2>
    <p>The MediaSource object represents a source of media data for an HTMLMediaElement. It keeps track of the <readyState/> for this source as well as a list of <SourceBuffer/> objects that can be used to add media data to the presentation. MediaSource objects are created by the web application and then attached to an HTMLMediaElement. The application uses the <SourceBuffer/> objects in <sourceBuffers/> to add media data to this source. The HTMLMediaElement fetches this media data from the <MediaSource/> object when it is needed during playback.</p>

    <pre class="idl">
[Constructor]
interface <dfn id="dom-mediasource">MediaSource</dfn> : EventTarget {
  // All the source buffers created by this object.
  readonly attribute <precoderef>SourceBufferList</precoderef> <precoderef>sourceBuffers</precoderef>;

  // Subset of sourceBuffers that provide data for the selected/enabled tracks.
  readonly attribute <precoderef>SourceBufferList</precoderef> <precoderef>activeSourceBuffers</precoderef>;

  attribute unrestricted double <precoderef>duration</precoderef>;

  <precoderef>SourceBuffer</precoderef> <premethodref>addSourceBuffer</premethodref>(DOMString type);
  void <premethodref>removeSourceBuffer</premethodref>(<precoderef>SourceBuffer</precoderef> sourceBuffer);

  enum State { "closed", "open", "ended" };
  readonly attribute State <precoderef>readyState</precoderef>;

  enum EndOfStreamError { "network", "decode" };
  void <premethodref>endOfStream</premethodref>(optional EndOfStreamError error);
};
    </pre>
    <h3 id="mediasource-methods">3.1. Methods and Attributes</h3>
    
    <p>The <codedfn>sourceBuffers</codedfn> attribute contains the list of <SourceBuffer/> objects associated with this <MediaSource/>. When <readyState/> equals <closed/> this list will be empty. Once <readyState/> transitions to <open/> SourceBuffer objects can be added to this list by using <addSourceBuffer/>.</p>

    <p>The <codedfn>activeSourceBuffers</codedfn> attribute contains the subset of <sourceBuffers/> that represents the <active-source-buffers/>.</p>

    <p>The <codedfn>duration</codedfn> attribute allows the web application to set the presentation duration. The duration is initially set to NaN when the <MediaSource/> object is created.</p>
    <p>On getting, run the following steps:</p>
    <ol>
      <li>If the <readyState/> attribute is <closed/> then return NaN and abort these steps.</li>
      <li>Return the current value of the attribute.</li>
    </ol>
    <p>On setting, run the following steps:</p>
    <ol>
      <li>If the value being set is negative or NaN then throw an <invalid-access-err/> exception and abort these steps.</li>
      <li>If the <readyState/> attribute is not <open/> then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>Update this attribute to the new value.</li>
      <li>Remove all media data that is beyond the new duration from all <SourceBuffer/> objects in <sourceBuffers/>.</li>
      <li>Update HTMLMediaElement.duration to the new duration and schedule the appropriate <videoref name="event-media-durationchange">durationchange</videoref> event to fire.</li>
      <li>If the HTMLMediaElement.currentTime is beyond the new duration, set HTMLMediaElement.currentTime to the new duration and trigger the appropriate seeking behavior.</li>
    </ol>

    <p>The <methoddfn name="addSourceBuffer">addSourceBuffer(<var title="true">type</var>)</methoddfn> method must run the following steps:</p>
    <ol>
      <li>If <var title="true">type</var> is null or an empty string then throw an <invalid-access-err/> exception and abort these steps.</li>
      <li>If <var title="true">type</var> contains a MIME type that is not supported or contains a MIME type that is not supported with the types specified for the other <SourceBuffer/> objects in <sourceBuffers/>, then throw a <not-supported-err/> exception and abort these steps.</li>
      <li>If the user agent can't handle any more SourceBuffer objects then throw a <quota-exceeded-err/> exception and abort these steps.</li>
      <li>If the <readyState/> attribute is not in the <open/> state then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>Create a new <SourceBuffer/> object and associated resources.</li>
      <li>Add the new object to <sourceBuffers/> and fire a <coderef>addsourcebuffer</coderef> event on that object.</li>
      <li>Return the new object.</li>
    </ol>
    <p>The <methoddfn name="removeSourceBuffer">removeSourceBuffer(<var title="true">sourceBuffer</var>)</methoddfn> method must run the following steps:</p>
    <ol>
      <li>If <var title="true">sourceBuffer</var> is null then throw an <invalid-access-err/> exception and abort these steps.</li>
      <li>If <sourceBuffers/> is empty then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>If <var title="true">sourceBuffer</var> specifies an object that is not in <sourceBuffers/> then throw a <not-found-err/> exception and abort these steps.</li>
      <li>Remove track information from <audiotracks/>, <videotracks/>, and <texttracks/> for all tracks associated with <var title="true">sourceBuffer</var> and fire a simple event named <videoref name="handler-tracklist-onchange">change</videoref> on the modified lists.</li>
      <li>If <var title="true">sourceBuffer</var> is in <activeSourceBuffers/>, then remove it from that list and fire a <removesourcebuffer/> event on that object.</li>
      <li>Remove <var title="true">sourceBuffer</var> from <sourceBuffers/> and fire a <removesourcebuffer/> event on that object.</li>
      <li>Destroy all resources for <var title="true">sourceBuffer</var>.</li>
    </ol>


    <p>The <codedfn>readyState</codedfn> attribute indicates the current state of the <MediaSource/> object. It can have the following values:</p>
    <dl>
      <dt><codedfn>&quot;closed&quot;</codedfn></dt>
      <dd>Indicates the source is not currently attached to a media element.</dd>

      <dt><codedfn>&quot;open&quot;</codedfn></dt>
      <dd>The source has been opened by a media element and is ready for data to be appended to the <SourceBuffer/> objects in <sourceBuffers/>.</dd>

      <dt><codedfn>&quot;ended&quot;</codedfn></dt>
      <dd>The source is still attached to a media element, but <methodref>endOfStream</methodref> has been called. Appending data to <SourceBuffer/> objects in this state is not allowed.</dd>
    </dl>
    <p>When the <MediaSource/> is created <readyState/> must be set to <closed/>.
    </p>


    <h5>End of stream error values:</h5>
    <dl>
      <dt><codedfn>&quot;network&quot;</codedfn></dt>
      <dd>The stream ended prematurely because of a network error. If the JavaScript code fetching media data encounters a network error it should use this status code to terminate playback. This will cause the media element's error handling code to run and the <code>error</code> attribute to be set to <videoref name="dom-mediaerror-media_err_network">MediaError.MEDIA_ERR_NETWORK</videoref></dd>

      <dt><codedfn>&quot;decode&quot;</codedfn></dt>
      <dd>The stream ended prematurely because there was an error while decoding the media data. If the JavaScript code fetching media data has problems parsing the data it should use this status code to terminate playback. This will cause the media element's error handling code to run and the <code>error</code> attribute to be set to <videoref name="dom-mediaerror-media_err_decode">MediaError.MEDIA_ERR_DECODE</videoref></dd>
    </dl>

    <p>The <methoddfn name="endOfStream">endOfStream(<var title="true">error</var>)</methoddfn> method must run the following steps:</p>
    <ol>
      <li>If the <readyState/> attribute is not in the <open/> state then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>Change the <readyState/> attribute value to <ended/>.</li>
      <dl class="switch">
          <dt>If <var title="true">error</var> is not set, null, or an empty string</dt>
          <dd>
	    <ol>
	      <li>Set the <duration/> attribute to the highest end timestamp across all <SourceBuffer/> objects in <sourceBuffers/>.</li>
	      <li>Notify the media element that it now has all of the media data. Playback should continue until all the media passed in via <append/> has been played.</li>
	    </ol>
	  </dd>
          <dt>If <var title="true">error</var> is set to <coderef>&quot;network&quot;</coderef></dt>
          <dd>Run the "If the connection is interrupted, causing the user agent to give up trying to fetch the resource" section of the <resource-fetch-algorithm/>.</dd>
          <dt>If <var title="true">error</var> is set to <coderef>&quot;decode&quot;</coderef></dt>
          <dd>Run the "If the media data is corrupted" section of the <resource-fetch-algorithm/>.</dd>
          <dt>Otherwise</dt>
          <dd>Throw an <invalid-access-err/> exception.</dd>
        </dl>
    </ol>


    <h3 id="mediasource-events">3.2. Event Summary</h3>
    <table>
      <thead>
        <tr>
          <th>Event name</th>
          <th>Interface</th>
          <th>Dispatched when...</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><codedfn>sourceopen</codedfn></td>
          <td><code>Event</code></td>
          <td>When <readyState/> transitions from <closed/> to <open/> or from <ended/> to <open/>.</td>
        </tr>
        <tr>
          <td><codedfn>sourceended</codedfn></td>
          <td><code>Event</code></td>
          <td>When <readyState/> transitions from <open/> to <ended/>.</td>
        </tr>
        <tr>
          <td><codedfn>sourceclose</codedfn></td>
          <td><code>Event</code></td>
	  <td>When <readyState/> transitions from <open/> to <closed/> or <ended/> to <closed/>.</td>
        </tr>
      </tbody>
    </table>

    <h3 id="mediasource-algorithms">3.3. Algorithms</h3>
    <h4 id="mediasource-attach">3.3.1 Attaching to a media element</h4>
    <p> A <MediaSource/> object can be attached to a media element by assigning a MediaSource object URL to the media element <media-src/> attribute or the src attribute of a &lt;source&gt; inside a media element. MediaSource object URLs are created by passing a MediaSource object to window.URL.createObjectURL().</p>
    <p>The following steps are run when a media element attempts the <resource-fetch-algorithm/> with a MediaSource object URL.</p>
    <ol>
      <dl class="switch">
        <dt>If <readyState/> is NOT set to <closed/></dt>
        <dd>Abort media element's <resource-fetch-algorithm/> and run the steps to report a <MEDIA_ERR_SRC_NOT_SUPPORTED/> error.</dd>
        <dt>Otherwise</dt>
        <dd>
          <ol>
            <li>Set <readyState/> attribute to <open/>.</li>
            <li>Fire a simple event named <coderef>sourceopen</coderef>.</li>
            <li>Allow the <resource-fetch-algorithm/> to progress based on data passed in via <append/>.</li>
          </ol>
        </dd>
      </dl>
    </ol>

    <h4 id="mediasource-detach">3.3.2 Detaching from a media element</h4>
    <p>The following steps are run in any case where the media element is going to transition to <videoref name="dom-media-network_empty">NETWORK_EMPTY</videoref> and fire an <videoref name="event-mediacontroller-emptied">emptied</videoref> event. These steps should be run right before the transition.</p>
    <ol>
      <li>Set <readyState/> attribute to <closed/>.</li>
      <li>Set <duration/> attribute to NaN.</li>
      <li>Remove all the <SourceBuffer/> objects from <sourceBuffers/> and fire a <coderef>removesourcebuffer</coderef> event for each one.</li>
      <li>Fire a simple event named <coderef>sourceclose</coderef>.</li>
    </ol>

    <h4 id="mediasource-seeking">3.3.3 Seeking</h4>
    <ol>
      <li>The media element <videoref name="dom-media-seeking">seeking algorithm</videoref> starts and has reached the stage where it is about to fire the <videoref name="event-media-seeking">seeking</videoref> event.</li>
      <li>
	<dl class="switch">
	  <dt>If the <readyState/> attribute is set to <ended/></dt>
	  <dd>
	    <ol>
	      <li>Set the <readyState/> attribute to <open/></li>
	      <li>Fire a simple event named <coderef>sourceopen</coderef> on the <MediaSource/> object.</li>
	    </ol>
	  </dd>
	  <dt>Otherwise</dt>
	  <dd>Continue</dd>
	</dl>
      </li>
      <li>The media element <videoref name="dom-media-seeking">seeking algorithm</videoref> fires the <videoref name="event-media-seeking">seeking</videoref> event</li>
      <li>The media element looks for <media-segments/> containing the desired seek point in each <SourceBuffer/> object in <activeSourceBuffers/></li>
      <dl class="switch">
	<dt>If one or more of the objects in <activeSourceBuffers/> is missing <media-segments/> for the desired seek point</dt>
	<dd>
	  <ol>
	    <li>Set <ready-state/> attribute to <have-metadata/> and fire the <appropriate-event/> for this transition.</li>
	    <li>The media element waits for the necessary <media-segments/> to be passed to <append/>. The web application can use <buffered/> to determine what the media element needs to resume playback.</li>
	  </ol>
	</dd>
	<dt>Otherwise</dt>
	<dd>Continue</dd>
      </dl>
      <li>The media element resets all decoders and initializes each one with data from the appropriate <init-segment/>.</li>
      <li>The media element feeds data from the <media-segments/> into the decoders until the desired seek point is reached.</li>
      <li>The media element resumes the <videoref name="dom-media-seeking">seeking algorithm</videoref> and fires the <videoref name="event-media-seeked">seeked</videoref> event indicating that the seek has completed.</li>
    </ol>


    <h4 id="buffer-monitoring">3.3.4 SourceBuffer Monitoring</h4>
    <p>The following steps are periodically run during playback to make sure that all of the <SourceBuffer/> objects in <activeSourceBuffers/> have enough data to ensure uninterrupted playback. Appending new segments and changes to <activeSourceBuffers/> also cause these steps to run because they affect the conditions that trigger state transitions. The web application can monitor changes in <ready-state/> to drive <media-segment/> appending.</p>
    <dl class="switch">
      <dt>If <buffered/> for all objects in <activeSourceBuffers/> do not contain <timeranges/> for the current playback position:</dt>
      <dd>
	<ol>
	  <li>Set <ready-state/> attribute to <have-metadata/> and fire the <appropriate-event/> for this transition.</li>
	  <li>Abort these steps.</li>
	</ol>
      </dd>
      <dt>If <buffered/> for all objects in <activeSourceBuffers/> contain <timeranges/> that include the current playback position and enough data to ensure uninterrupted playback:</dt>
      <dd>
	<ol>
	  <li>Set <ready-state/> attribute to <have-enough-data/> and fire the <appropriate-event/> for this transition.</li>
	  <li>Playback may resume at this point if it was previously suspended by a transition to <have-current-data/>.</li>
	  <li>Abort these steps.</li>
	</ol>
      </dd>
      <dt>If <buffered/> for at least one object in <activeSourceBuffers/> contains a <timerange/> that includes the current playback position but not enough data to ensure uninterrupted playback:</dt>
      <dd>
	<ol>
	  <li>Set <ready-state/> attribute to <have-future-data/> and fire the <appropriate-event/> for this transition.</li>
	  <li>Playback may resume at this point if it was previously suspended by a transition to <have-current-data/>.</li>
	  <li>Abort these steps.</li>
	</ol>
      </dd>
      <dt>If <buffered/> for at least one object in <activeSourceBuffers/> contains a <timerange/> that ends at the current playback position and does not have a range covering the time immediately after the current position:</dt>
      <dd>
	<ol>
	  <li>Set <ready-state/> attribute to <have-current-data/> and fire the <appropriate-event/> for this transition.</li>
	  <li>Playback is suspended at this point since the media element doesn't have enough data to advance the timeline.</li>
	  <li>Abort these steps.</li>
	</ol>
      </dd>
    </dl>

    <h4 id="active-source-buffer-changes">3.3.5 Changes to selected/enabled track state.</h4>
    <p>During playback <activeSourceBuffers/> needs to be updated if the <videoref name="dom-videotrack-selected">selected video track</videoref>, the <videoref name="dom-audiotrack-enabled">enabled audio tracks</videoref>, or a text track <videoref name="dom-texttrack-mode">mode</videoref> changes. When one or more of these changes occur the following steps need to be followed.</p>
    <dl class="switch">
      <dt>If the selected video track changes</dt>
      <dd>
	<ol>
	  <li>If the <SourceBuffer/> associated with the previously selected video track is not associated with any other enabled tracks then remove it from <activeSourceBuffers/></li>
	  <li>If the <SourceBuffer/> associated with the newly selected video track is not already in <activeSourceBuffers/> then add it.</li>
	</ol>
      </dd>
      <dt>If an audio track becomes disabled and the <SourceBuffer/> associated with this track is not associated with any other enabled or selected track</dt>
      <dd>Remove the <SourceBuffer/> associated with the audio track from <activeSourceBuffers/></dd>
      <dt>If an audio track becomes enabled and the <SourceBuffer/> associated with this track is not already in <activeSourceBuffers/></dt>
      <dd>Add the <SourceBuffer/> associated with the audio track to <activeSourceBuffers/></dd>
      <dt>If a text track <videoref name="dom-texttrack-mode">mode</videoref> becomes <videoref name="dom-texttrack-disabled">&quot;disabled&quot;</videoref> and the <SourceBuffer/> associated with this track is not associated with any other enabled or selected track</dt>
      <dd>Remove the <SourceBuffer/> associated with the text track from <activeSourceBuffers/></dd>
      <dt>If a text track <videoref name="dom-texttrack-mode">mode</videoref> becomes <videoref name="dom-texttrack-showing">&quot;showing&quot;</videoref> or <videoref name="dom-texttrack-hidden">&quot;hidden&quot;</videoref> and the <SourceBuffer/> associated with this track is not already in <activeSourceBuffers/></dt>
      <dd>Add the <SourceBuffer/> associated with the text track to <activeSourceBuffers/></dd>
    </dl>


   <h2 id="sourcebuffer">4. SourceBuffer Object</h2>
    <pre class="idl">
interface <dfn id="dom-sourcebuffer">SourceBuffer</dfn> : EventTarget {
  // Returns the time ranges buffered.
  readonly attribute TimeRanges <precoderef>buffered</precoderef>;

  // Applies an offset to media segment timestamps.
  attribute double <precoderef>timestampOffset</precoderef>;

  // Append segment data.
  void <premethodref>append</premethodref>(Uint8Array data);

  // Abort the current segment append sequence.
  void <premethodref>abort</premethodref>();
};
    </pre>
   <p>The <codedfn>buffered</codedfn> attribute indicates what <timeranges/> are buffered in the <SourceBuffer/>. When the attribute is read the following steps must occur:</p>
   <ol>
     <li>If this object has been removed from the <sourceBuffers/> attribute of the <MediaSource/> object that created it then throw an <invalid-state-err/> exception and abort these steps.</li>
     <li>Return <timeranges/> for the <media-segments/> buffered.</li>
   </ol>

   <p>The <codedfn>timestampOffset</codedfn> attribute controls the offset applied to timestamps inside subsequent <media-segments/> that are appended to this <SourceBuffer/>. The <timestampOffset/> is initially set to 0 which indicates that no offset is being applied. On getting, the initial value or the last value that was successfully set is returned. On setting, run following steps:</p>
   <ol>
     <li>If this object has been removed from the <sourceBuffers/> attribute of the <MediaSource/> object that created it, then throw an <invalid-state-err/> exception and abort these steps.</li>
     <li>If the <readyState/> attribute of the <MediaSource/> object that created this object is not in the <open/> state, then throw an <invalid-state-err/> exception and abort these steps.</li>
     <li>If this object is waiting for the end of a <media-segment/> to be appended, then throw an <invalid-state-err/> and abort these steps.</li>
     <li>Update the attribute to the new value.</li>
   </ol>

    <p>The <methoddfn name="append">append(<var title="true">data</var>)</methoddfn> method must run the following steps:</p>
    <ol>
      <li>If <var title="true">data</var> is null then throw an <invalid-access-err/> exception and abort these steps.</li>
      <li>If this object has been removed from the <sourceBuffers/> attribute of the <MediaSource/> object that created it then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>If the <readyState/> attribute of the <MediaSource/> object that created this object is not in the <open/> state then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>If <var title="true">data</var>.byteLength is 0 abort these steps.</li>
      <li>Add <var title="true">data</var> to the source buffer:
	<dl class="switch">
	  <dt>If <var title="true">data</var> is part of a <media-segment/> and <timestampOffset/> is not 0:</dt>
	  <dd>
	    <ol>
	      <li>Find all timestamps inside <var title="true">data</var> and add <timestampOffset/> to them.</li>
	      <li>If any of the modified timestamps are earlier than the <presentation-start-time/>, run the media element's error handling code to signal a <videoref name="dom-mediaerror-media_err_decode">MediaError.MEDIA_ERR_DECODE</videoref> error, and abort these steps.</li>
	      <li>Copy the contents of <var title="true">data</var>, with the modified timestamps, into the source buffer.</li>
	    </ol>
	  </dd>
	  <dt>Otherwise</dt>
	  <dd>Copy the contents of <var title="true">data</var> into the source buffer.</dd>
	</dl>
      </li>
      <li>Handle end of segment cases:</li>
      <dl class="switch">
	<dt>If <var title="true">data</var> completes the first <init-segment/> appended to the <source-buffer/> run the following steps:</dt>
	<dd>
	  <ol>
	    <li>Update <duration/> attribute if it currently equals NaN:</li>
	    <dl class="switch">
	      <dt>If the initialization segment contains a duration:</dt>
	      <dd>Set the <duration/> attribute to the value in the initialization segment.</dd>
	      <dt>Otherwise:</dt>
	      <dd>Set the <duration/> attribute to positive Infinity.</dd>
	    </dl>
	    <li>Handle state transitions:</li>
	    <dl class="switch">
	      <dt>If the <ready-state/> attribute is <have-nothing/>:</dt>
	      <dd>Set <ready-state/> attribute to <have-metadata/> and fire the <appropriate-event/> for this transition.</dd>
	      <dt>If the <ready-state/> attribute is greater than <have-current-data/> and the <init-segment/> contains the first video or first audio track in the presentation:</dt>
	      <dd>
		Set <ready-state/> attribute to <have-metadata/> and fire the <appropriate-event/> for this transition.
	      </dd>
	      <dt>Otherwise:</dt>
	      <dd>Continue</dd>
	    </dl>
	    <li>Update <audiotracks/></li>
	    <dl class="switch">
	      <dt>If <init-segment/> contains the first audio track:</dt>
	      <dd>
		<ol>
		  <li>Add an <audio-track/> and mark it as enabled.</li>
		  <li>Add this <SourceBuffer/> to <activeSourceBuffers/>.</li>
		</ol>
	      </dd>
	      <dt>If <init-segment/> contains audio tracks beyond those already in the presentation:</dt>
	      <dd>Add a disabled <audio-track/> for each audio track in the <init-segment/>.</dd>
	    </dl>
	    <li>Update <videotracks/>:</li>
	    <dl class="switch">
	      <dt>If <init-segment/> contains the first video track:</dt>
	      <dd>
		<ol>
		  <li>Add a <video-track/> and mark it as selected.</li>
		  <li>Add this <SourceBuffer/> to <activeSourceBuffers/>.</li>
		</ol>
	      </dd>
	      <dt>If <init-segment/> contains the video tracks beyond those already in the presentation:</dt>
	      <dd>Add a disabled <video-track/> for each video track in the <init-segment/>.</dd>
	    </dl>
	    <li>Update <texttracks/></li>
	    <dl class="switch">
	      <dd>
		<ol>
		  <li>Add a <text-track/> for each text track in the <init-segment/>.</li>
		  <li>If the text track <videoref name="dom-texttrack-mode">mode</videoref> is <videoref name="dom-texttrack-showing">&quot;showing&quot;</videoref> or <videoref name="dom-texttrack-hidden">&quot;hidden&quot;</videoref> then add this <SourceBuffer/> to <activeSourceBuffers/>.</li>
		</ol>
	      </dd>
	    </dl>
	  </ol>
	</dd>
	<dt>If the <ready-state/> attribute is <have-metadata/> and <var title="true">data</var> causes all objects in <activeSourceBuffers/> to have media data for the current playback position.</dt>
	<dd>Set <ready-state/> attribute to <have-current-data/> and fire the <appropriate-event/> for this transition.</dd>
	<dt>If the <ready-state/> attribute is <have-current-data/> and <var title="true">data</var> causes all objects in <activeSourceBuffers/> to have media data beyond the current playback position.</dt>
	<dd>Set <ready-state/> attribute to <have-future-data/> and fire the <appropriate-event/> for this transition.</dd>
	<dt>If the <ready-state/> attribute is <have-future-data/> and <var title="true">data</var> causes all objects in <activeSourceBuffers/> to have enough data to start playback.</dt>
	<dd>Set <ready-state/> attribute to <have-enough-data/> and fire the <appropriate-event/> for this transition.</dd>
	<dt>If the <media-segment/> contains data beyond the current <duration/></dt>
	<dd>Update the <duration/> attribute to reflect the end of the appended data. (ie Highest end timestamp reported by HTMLMediaElement.buffered)</dd>
      </dl>
    </ol>

    <p>The <methoddfn name="abort">abort()</methoddfn> method must run the following steps:</p>
    <ol>
      <li>If this object has been removed from the <sourceBuffers/> attribute of the <MediaSource/> object that created it then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>If the <readyState/> attribute of the <MediaSource/> object that created this object is not in the <open/> state then throw an <invalid-state-err/> exception and abort these steps.</li>
      <li>The media element aborts parsing the current segment.</li>
      <dl class="switch">
	<dt>If waiting for the start of a new segment</dt>
	<dd>Continue</dd>
	<dt>If the current segment is an <init-segment/></dt>
	<dd>Flush any data associated with this partial segment.</dd>
	<dt>If the current segment is a <media-segment/></dt>
	<dd>The media element may keep any media data it finds valuable in the partial segment. For example if the abort happens in the middle of a 10 second <media-segment/>, the media element may choose to keep the 5 seconds of media data it has already parsed in the source buffer. <buffered/> will reflect what data, if any, was kept.</dd>
      </dl>
      <li>The media element resets the segment parser so that it can accept a new <init-segment/> or <media-segment/>.</li>
    </ol>

        <h2 id="sourcebufferlist">5. SourceBufferList Object</h2>
    <p>SourceBufferList is a simple container object for <SourceBuffer/> objects. It provides read-only array access and fires events when the list is modified.</p>

    <pre class="idl">
interface <dfn id="dom-sourcebufferlist">SourceBufferList</dfn> : EventTarget {
  readonly attribute unsigned long <precoderef>length</precoderef>;
  <precoderef>getter</precoderef> <precoderef>SourceBuffer</precoderef> (unsigned long index);
};
    </pre>
    <h3 id="sourcebufferlist-methods">5.1. Methods and Attributes</h3>
    <p>The <codedfn>length</codedfn> attribute indicates the number of <SourceBuffer/> objects in the list.</p>
    <p>The <dfn id="dom-getter"><code>getter SourceBuffer (unsigned long <var title="true">index</var>)</code></dfn> method allows the SourceBuffer objects in the list to be accessed with an array operator (i.e. []). This method must run the following steps:</p>
    <ol>
      <li>If <var title="true">index</var> is greater than or equal to the <length/> attribute then return undefined and abort these steps.</li>
      <li>Return the <var title="true">index</var>'th <SourceBuffer/> object in the list.</li>
    </ol>

    <h3 id="sourcebufferlist-events">5.2. Event Summary</h3>
    <table>
      <thead>
        <tr>
          <th>Event name</th>
          <th>Interface</th>
          <th>Dispatched when...</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><codedfn>addsourcebuffer</codedfn></td>
          <td><code>Event</code></td>
          <td>When a <SourceBuffer/> is added to the list.</td>
        </tr>
        <tr>
          <td><codedfn>removesourcebuffer</codedfn></td>
          <td><code>Event</code></td>
          <td>When a <SourceBuffer/> is removed from the list.</td>
        </tr>
      </tbody>
    </table>

    <h2 id="byte-stream-formats">6. Byte Stream Formats</h2>
    <p>The bytes provided through <append/> for a <SourceBuffer/> form a logical byte stream. The format of this byte stream depends on the media container format in use and is defined in a byte stream format specification. Byte stream format specifications based on WebM and the ISO Base Media File Format are provided below. If these formats are supported then the byte stream formats described below must be supported.</p>
    <p>This section provides general requirements for all byte stream formats:</p>
    <ul>
      <li>A byte stream format specification may define <init-segments/> and must define <media-segments/>.</li>
      <li>It must be possible to identify segment boundaries and segment type (initialization or media) by examining the byte stream alone.</li>
      <li>The combination of an Initialization Segment and any contiguous sequence of Media Segments associated with it must:
	<ol>
	  <li>Identify the number and type (audio, video, text, etc.) of tracks in the Segments</li>
	  <li>Identify the decoding capabilities needed to decode each track (i.e. codec and codec parameters)</li>
	  <li>If a track is encrypted, provide any encryption parameters necessary to decrypt the content (except the encryption key itself)</li>
	  <li>For each track, provide all information necessary to decode and render the earliest <random-access-point/> in the sequence of Media Segments and all subsequent samples in the sequence (in presentation time). This includes, in particular,
	    <ul>
	      <li>Information that determines the <intrinsic-width-and-height/> of the video (specifically, this requires either the picture or pixel aspect ratio, together with the encoded resolution).</li>
	      <li>Information necessary to convert the video decoder output to a format suitable for display</li>
	    </ul>
	  </li>
	  <li>Identify the global presentation timestamp of every sample in the sequence of Media Segments</li>
	  <p>For example, if I1 is associated with M1, M2, M3 then the above must hold for all the combinations I1+M1, I1+M2, I1+M1+M2, I1+M2+M3, etc.</p>
	</ol>
      </li>
    </ul>
    <p>Byte stream specifications must at a minimum define constraints which ensure that the above requirements hold. Additional constraints may be defined, for example to simplify implementation.</p>

    <p>Initialization segments are an optimization. They allow a byte stream format to avoid duplication of information in Media Segments that is the same for many Media Segments. Byte stream format specifications need not specify Initialization Segment formats, however. They may instead require that such information is duplicated in every Media Segment.</p>

    <h3 id="webm">6.1 WebM Byte Streams</h3>
    <div class="nonnormative">
      <p>This section defines segment formats for implementations that choose to support WebM.</p>
      <h4 id="webm-init-segments">6.1.1. Initialization Segments</h4>
      <p>A WebM <init-segment/> must contain a subset of the elements at the start of a typical WebM file.</p>
      <p>The following rules apply to WebM initialization segments:</p>
      <ol>
	<li>The <init-segment/> must start with an <webm-ebml-header/> element, followed by a <webm-segment/> header.</li>
	<li>The size value in the <webm-segment/> header must signal an "unknown size" or contain a value large enough to include the <webm-info/> and <webm-tracks/> elements that follow.</li>
	<li>Exactly one <webm-info/> element must appear after the <webm-segment/> header.</li>
	<li>Exactly one <webm-tracks/> element must appear after the <webm-info/> element.</li>
	<li><webm-meta-seek/>, <webm-cues/>, <webm-chapters/>, and various <webm-global-elements/> may follow the <webm-segment/> header but the contents of these elements will be ignored.<br/>Note: This enables the use case where the contents of a WebM file are simply appended without any inspection or reformatting.</li>
      </ol>

      <h4 id="webm-media-segments">6.1.2. Media Segments</h4>
      <p>A WebM <media-segment/> is a single <webm-cluster/> element.</p>
      <p>The following rules apply to WebM media segments:</p>
      <ol>
	<li>The Timecode element in the <webm-cluster/> contains a presentation timestamp in TimecodeScale units.</li>
	<li>The TimecodeScale in the <webm-init-segment/> most recently appended applies to all timestamps in the <webm-cluster/></li>
	<li>The Cluster header may contain an "unknown" size value. If it does then the end of the cluster is reached when another <webm-cluster/> header or an element header that indicates the start of an <webm-init-segment/> is encountered.</li>
	<li>Block &amp; SimpleBlock elements must be in time increasing order consistent with the <webm-spec/>.</li>
	<li>If the most recent <webm-init-segment/> describes multiple tracks, then blocks from all the tracks must be present and interleaved in time increasing order.</li>
	<li><webm-cues/> or <webm-chapters/> elements may follow a <webm-cluster/> element. These elements should be accepted and ignored by the user agent.</li>
      </ol>

      <h4 id="webm-random-access-points">6.1.3. Random Access Points</h4>
      <p>A SimpleBlock element with its Keyframe flag set signals the location of a <random-access-point/> for that track. Media segments containing multiple tracks are only considered a random access point if the first SimpleBlock for each track has its Keyframe flag set. The order of the multiplexed blocks should conform to the <webm-muxer-guidelines/>.</p>
    </div>

    <h3 id="iso">6.2 ISO Base Media File Format Byte Streams</h3>
    <div class="nonnormative">
      <p>This section defines segment formats for implementations that choose to support the ISO Base Media File Format
	<iso-14496-12/> (ISO BMFF).</p> 
      <h4 id="iso-init-segments">6.2.1. Initialization Segments</h4>
      <p>An ISO BMFF <init-segment/> must contain a single Movie Header Box (<iso-box>moov</iso-box>). The tracks in the Movie Header Box must not contain any samples (i.e. the <iso-var>entry_count</iso-var> in the <iso-box>stts</iso-box>, <iso-box>stsc</iso-box> and <iso-box>stco</iso-box> boxes must be set to zero). A Movie Extends (<iso-box>mvex</iso-box>) box must be contained in the
	Movie Header Box to indicate that Movie Fragments are to be expected.</p>
      <p>The <init-segment/> may contain Edit Boxes (<iso-box>edts</iso-box>) which provide a mapping of composition times for each track to the global presentation time.</p>
      <h4 id="iso-media-segments">6.2.2. Media Segments</h4>
      <p>An ISO BMFF <media-segment/> must contain a single Movie Fragment Box (<iso-box>moof</iso-box>) followed by one or more Media Data Boxes (<iso-box>mdat</iso-box>).</p>
      <p>The following rules apply to ISO BMFF media segments:</p>
      <ol>
	<li>The Movie Fragment Box must contain at least one Track Fragment Box (<iso-box>traf</iso-box>).</li>
	<li>The Movie Fragment Box must use movie-fragment relative addressing and the flag <iso-var>default-base-is-moof</iso-var> must be set; absolute byte-offsets must not be used.</li>
	<li>External data references must not be used.</li>
	<li>If the Movie Fragment contains multiple tracks, the duration by which each track extends should be as close to equal as practical.</li>
	<li>Each Track Fragment Box must contain a Track Fragment Decode Time Box (<iso-box>tfdt</iso-box>)</li>
	<li>The Media Data Boxes must contain all the samples referenced by the Track Run Boxes (<iso-box>trun</iso-box>) of the Movie Fragment Box.</li>
      </ol>

      <h4 id="iso-random-access-points">6.2.3. Random Access Points</h4>
      <p>A <random-access-point/> as defined in this specification corresponds to a Stream Access Point of type 1 or 2 as defined in Annex I of <iso-14496-12/>.</p>
    </div>

    <h2 id="examples">7. Examples</h2>
    <p>Example use of the Media Source Extensions</p>
    <div class="block">
      <div class="blockContent">
        <pre class="code">
&lt;script&gt;
  function onSourceOpen(videoTag, e) {
    var mediaSource = e.target;
    var sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vorbis,vp8"');

    videoTag.addEventListener('seeking', onSeeking.bind(videoTag, mediaSource));
    videoTag.addEventListener('progress', onProgress.bind(videoTag, mediaSource));

    var initSegment = GetInitializationSegment();

    if (initSegment == null) {
      // Error fetching the initialization segment. Signal end of stream with an error.
      mediaSource.endOfStream("network");
      return;
    }

    // Append the initialization segment.
    sourceBuffer.append(initSegment);

    // Append some initial media data.
    appendNextMediaSegment(mediaSource);
  }

  function appendNextMediaSegment(mediaSource) {
    if (mediaSource.readyState == "ended")
      return;

    // If we have run out of stream data, then signal end of stream.
    if (!HaveMoreMediaSegments()) {
      mediaSource.endOfStream();
      return;
    }

    var mediaSegment = GetNextMediaSegment();

    if (!mediaSegment) {
       // Error fetching the next media segment.
       mediaSource.endOfStream("network");
       return;
    } 

    mediaSource.sourceBuffers[0].append(mediaSegment);
  }

  function onSeeking(mediaSource, e) {
    var video = e.target;

    // Abort current segment append.
    mediaSource.sourceBuffers[0].abort();

    // Notify the media segment loading code to start fetching data at the
    // new playback position.
    SeekToMediaSegmentAt(video.currentTime);

    // Append media segments from the new playback position.
    appendNextMediaSegment(mediaSource);
    appendNextMediaSegment(mediaSource);
  }

  function onProgress(mediaSource, e) {
    appendNextMediaSegment(mediaSource);
  }
&lt;/script&gt;

&lt;video id="v" autoplay&gt; &lt;/video&gt;

&lt;script&gt;
  var video = document.getElementById('v');
  var mediaSource = new MediaSource();
  mediaSource.addEventListener('sourceopen', onSourceOpen.bind(this, video));
  video.src = window.URL.createObjectURL(mediaSource);
&lt;/script&gt;
        </pre>
      </div>
    </div>

    <h2 id="revision-history">8. Revision History</h2>
    <table>
      <thead>
        <tr>
          <th>Version</th>
          <th>Comment</th>
        </tr>
      </thead>
      <tbody>
	<tr>
	  <td>17 August 2012</td>
          <td>Minor editorial fixes.</td>
        </tr>
        <tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/29687c019735/media-source/media-source.html">09 August 2012</a></td>
          <td>Change presentation start time to always be 0 instead of using format specific rules about the first media segment appended.</td>
        </tr>
	<tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/087ea42f59c8/media-source/media-source.html">30 July 2012</a></td>
          <td>Added SourceBuffer.timestampOffset and MediaSource.duration.</td>
        </tr>
        <tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/ab36e8e882c6/media-source/media-source.html">17 July 2012</a></td>
          <td>Replaced SourceBufferList.remove() with MediaSource.removeSourceBuffer().</td>
        </tr>
	<tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/b499a199e427/media-source/media-source.html">02 July 2012</a></td>
          <td>Converted to the object-oriented API</td>
        </tr>
	<tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/9bbfe09653e4/media-source/media-source.html">26 June 2012</a></td>
          <td>Converted to Editor's draft.</td>
        </tr>
	<tr>
	  <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/e433598d22a7/media-source/media-source.html">0.5</a></td>
          <td>Minor updates before proposing to W3C HTML-WG.</td>
        </tr>
        <tr>
          <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.4/draft-spec/mediasource-draft-spec.html">0.4</a></td>
          <td>Major revision. Adding source IDs, defining buffer model, and clarifying byte stream formats.</td>
        </tr>
	<tr>
          <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.3/draft-spec/mediasource-draft-spec.html">0.3</a></td>
          <td>Minor text updates.</td>
        </tr>
        <tr>
          <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.2/draft-spec/mediasource-draft-spec.html">0.2</a></td>
          <td>Updates to reflect initial WebKit implementation.</td>
        </tr>
        <tr>
          <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.1/draft-spec/mediasource-draft-spec.html">0.1</a></td>
          <td>Initial Proposal</td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
